services:
  # PostgreSQL Database Service
  postgres:
    image: postgres:15-alpine
    container_name: interview-assistant-db
    environment:
      POSTGRES_DB: interview_assistant
      POSTGRES_USER: interview_user
      POSTGRES_PASSWORD: interview_password_2024
      POSTGRES_HOST_AUTH_METHOD: trust
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5432:5432"
    networks:
      - interview-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U interview_user -d interview_assistant"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache Service (for enhanced caching)
  redis:
    image: redis:7-alpine
    container_name: interview-assistant-cache
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - interview-network
    restart: unless-stopped
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # FastAPI Application Service
  app:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: interview-assistant-app
    environment:
      # Database Configuration
      DATABASE_URL: postgresql://interview_user:interview_password_2024@postgres:5432/interview_assistant
      
      # Redis Configuration
      REDIS_URL: redis://redis:6379/0
      
      # Application Settings
      ENVIRONMENT: production
      DEBUG: false
      
      # Codespace Configuration (for GitHub Codespaces)
      CODESPACE_NAME: ${CODESPACE_NAME:-}
      GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN: ${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN:-}
      
      # OpenAI Configuration (replace with your API key)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-your_openai_api_key_here}
      
      # Security Settings
      SECRET_KEY: ${SECRET_KEY:-your_secret_key_here_change_in_production}
      
      # Session Settings
      SESSION_EXPIRE_HOURS: 24
      MAX_ACTIVE_SESSIONS: 100
      
      # AI Response Settings
      AI_MODEL: gpt-3.5-turbo
      MAX_CONTEXT_MESSAGES: 10
      AI_TEMPERATURE: 0.7
      
      # Caching Settings
      CACHE_TTL_SECONDS: 3600
      MAX_CACHE_SIZE: 1000
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - interview-network
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Nginx Reverse Proxy (optional, for production)
  nginx:
    image: nginx:alpine
    container_name: interview-assistant-proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - app
    networks:
      - interview-network
    restart: unless-stopped
    profiles:
      - production

# Named volumes for data persistence
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local

# Custom network for service communication
networks:
  interview-network:
    driver: bridge